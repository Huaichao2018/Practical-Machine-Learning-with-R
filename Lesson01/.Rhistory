# Generating Features
# Date Features
#Fetch the current date
current_date=Sys.time()
## Print the date
formatted_date <- as.POSIXlt(current_date)
#Fetch the year
year=format(formatted_date, "%Y")
#Fetch the month
month=format(formatted_date, "%m")
#Fetch the date
day=format(formatted_date, "%d")
#Fetch the day of week
weekday=format(formatted_date, "%w")
## Time Features
library(lubridate)
install.packages("stringi")
library(lubricate)
library(lubridate)
install.packages(lubridate)
install.packages("lubridate")
library(lubridate)
install.packages("lubridate")
install.packages("glue",type="win.binary")
install.packages("stringi",type="win.binary")
install.packages("stringr",type="win.binary")
install.packages("lubridate",type="win.binary")
library(lubridate)
#Hour of Day
hour=formatted_date$hour
hour=hour(formatted_date)
#Extract Minute
min=minute(formatted_date)
#Time series features
library(caret)
data(GermanCredit)
library(MASS)
install.packages('MASS')
library(MASS)
install.package('MASS')
install.packages('MASS')
library(MASS)
data()
save()
#Fetch the day of week
weekday=format(formatted_date, "%w")
#Fetch the day of week
weekday=format(formatted_date, "%w")
save(data1, file = "data.RData")
save(data1, file = "Exercise01.RData")
save(data1, file = "Exercise01.r.RData")
# Print a
print("Hi")
data = read.csv("mydata.csv")
# Print a
print("Hi")
# Set the working directory
setwd("C:/R")
# Print a
print("Hi")
# Set the working directory
setwd("D:\GitHub\Practical-Machine-Learning-with-R\Lesson01")
# Set the working directory
setwd('D:\GitHub\Practical-Machine-Learning-with-R\Lesson01')
#Read data from a CSV file
data = read.csv("mydata.csv")
# Set the working directory
setwd('D:/GitHub/Practical-Machine-Learning-with-R/Lesson01')
#Read data from a CSV file
data = read.csv("mydata.csv")
data
data
# Print a
print("Hi")
# Set the working directory
setwd('D:/GitHub/Practical-Machine-Learning-with-R/Lesson01')
#Read data from a CSV file
data = read.csv("mydata.csv")
data
#Create a new row in the dataframe
data2 = rbind(data,list(1,2,3))
data2
# Print a
print("Hi")
# Set the working directory
setwd('D:/GitHub/Practical-Machine-Learning-with-R/Lesson01')
#Read data from a CSV file
data = read.csv("mydata.csv",header=T,sep=",")
# Print a
print("Hi")
# Set the working directory
setwd('D:/GitHub/Practical-Machine-Learning-with-R/Lesson01')
#Read data from a CSV file
data = read.csv("mydata.csv",header=T,sep=",")
data
# Print a
print("Hi")
# Set the working directory
setwd('D:/GitHub/Practical-Machine-Learning-with-R/Lesson01')
#Read data from a CSV file
data = read.csv("mydata.csv")
data
#Create a new row in the dataframe
data2 = rbind(data,list(1,2,3))
data2
#Fetch the current date
current_date=Sys.time()
## print the date
formatted_date <- as.POSIXlt(current_date)
#Fetch the year
year=format(formatted_date, "%Y")
#Fetch the month
month=format(formatted_date, "%m")
#Fetch the date
day=format(formatted_date, "%d")
#Fetch the day of week
weekday=format(formatted_date, "%w")
## Time Features
library(lubridate)
#Hour of Day
hour=formatted_date$hour
hour=hour(formatted_date)
#Extract Minute
min=minute(formatted_date)
#Time series features
library(caret)
packages.install('caret')
install.packages('caret')
#Time series features
library(caret)
data(GermanCredit)
duration<- GermanCredit$Duration #take the duration column
summary(duration)
library(ggplot2)
ggplot(data=GermanCredit, aes(x=GermanCredit$Duration)) +
geom_density(fill='lightblue') +
geom_rug() +
labs(x='mean Duration')
#Creating Bins
# set up boundaries for intervals/bins
breaks <- c(0,10,20,30,40,50,60,70,80)
# specify interval/bin labels
labels <- c("<10", "10-20)", "20-30)", "30-40)", "40-50)", "50-60)", "60-70)", "70-80")
# bucketing data points into bins
bins <- cut(duration, breaks, include.lowest = T, right=FALSE, labels=labels)
# inspect bins
summary(bins)
#Ploting the bins
plot(bins, main="Frequency", ylab="Duration",col="bisque")
library(caret)
data(GermanCredit)
#See the structure of the dataset
str(GermanCredit)
#Calculate mean
mean =mean(GermanCredit$Amount)
#Calculate standard deviation
standard_dev=sd(GermanCredit$Amount)
#Calculate median
median=median(GermanCredit$Amount)
#Identify maximum
max=max(GermanCredit$Amount)
#Identify minimum
min=min(GermanCredit$Amount)
library(e1071)                    # load e1071
install.packages('e1071')
library(e1071)                    # load e1071
skewness=skewness(GermanCredit$Amount)
histogram(PimaIndiansDiabetes$glucose)
#Skewness
library(mlbench)
data(PimaIndiansDiabetes)
install/packages('mlbench')
install.packages('mlbench')
#install.packages('mlbench')
data(PimaIndiansDiabetes)
#Printing the skewness of the columns
#Not skewed
skewness(PimaIndiansDiabetes$glucose)
#Skewness
install.packages('mlbench')
library(mlbench)
#install.packages('mlbench')
data(PimaIndiansDiabetes)
#Printing the skewness of the columns
#Not skewed
skewness(PimaIndiansDiabetes$glucose)
histogram(PimaIndiansDiabetes$glucose)
#Highly skewed
skewness(PimaIndiansDiabetes$age)
#Highly skewed
skewness(PimaIndiansDiabetes$age)
histogram(PimaIndiansDiabetes$age)
#Log Transformation
transformed_data=log(PimaIndiansDiabetes$age)
#View histogram
histogram(transformed_data)
#Time series features
library(caret)
data(GermanCredit)
duration<- GermanCredit$Duration #take the duration column
summary(duration)
library(ggplot2)
ggplot(data=GermanCredit, aes(x=GermanCredit$Duration)) +
geom_density(fill='lightblue') +
geom_rug() +
labs(x='mean Duration')
#Creating Bins
# set up boundaries for intervals/bins
breaks <- c(0,10,20,30,40,50,60,70,80)
# specify interval/bin labels
labels <- c("<10", "10-20)", "20-30)", "30-40)", "40-50)", "50-60)", "60-70)", "70-80")
# bucketing data points into bins
bins <- cut(duration, breaks, include.lowest = T, right=FALSE, labels=labels)
# inspect bins
summary(bins)
#Ploting the bins
plot(bins, main="Frequency", ylab="Duration",col="bisque")
library(ggplot2)
df<-iris
df<-df[df$Species="setosa",]
df<-iris
df<-df[df$Species="setosa",]
df1<-subset[df$Species="setosa",]
df1<-df[which($Species="setosa")]
df1<-df[which(df$Species="setosa")]
df1<-df[which(df$Species='setosa')]
df1<-df[which(df$Species=='setosa')]
df<-iris
df
df<-iris
df
df1<-subset(df,Species=='setosa')
library(kdensity)
df<-iris
df
df1<-subset(df,Species=='setosa')
df1
library(kdensity)
install.packages('kdensity')
dist <- kdensity(df$Sepal.Length)
plot(dist)
library(kdensity)
dist <- kdensity(df$Sepal.Length)
plot(dist)
dist <- kdensity(df$Sepal.Width)
plot(dist)
df<-iris
df
df1<-subset(df,Species=='setosa')
df1
library(kdensity)
dist <- kdensity(df1$Sepal.Length)
plot(dist)
dist <- kdensity(df1$Sepal.Width)
plot(dist)
#Log Transformation
transformed_data=log(PimaIndiansDiabetes$age)
data(PrimaIndiansDiabetes)
data(PimaIndiansDiabetes)
#Log Transformation
transformed_data=log(PimaIndiansDiabetes$age)
#View histogram
histogram(transformed_data)
library(MASS)
box_cox = boxcox(PimaIndiansDiabetes$age ~ 1, lambda = seq(-6,6,0.1))
cox = data.frame(box_cox$x, box_cox$y)
cox2 = cox[with(cox, order(-cox$box_cox.y)),] # Order the new data frame by decreasing y
cox2[1,]                                  # Display the lambda with the greatest
lambda = cox2[1, "box_cox.x"]                 # Extract that lambda
transformed_box_cox = (PimaIndiansDiabetes$age ^ lambda - 1)/lambda   # Transform the original data
#View histogram
histogram(transformed_box_cox)
data(GermanCredit)
str(GermanCredit)
#Copy a existing column into a new column
GermanCredit$NewField2=GermanCredit$Purpose.Repairs
str(GermanCredit)
#Adding new features to a R datadrame
library(caret)
#Adding new features to a R datadrame
library(caret)
data(GermanCredit)
#Assign the value to the new field
GermanCredit$NewField=1
str(GermanCredit)
#Copy a existing column into a new column
GermanCredit$NewField2=GermanCredit$Purpose.Repairs
str(GermanCredit)
#Loading the library
library(caret)
# load the German Credit Data
data(GermanCredit)
# calculating the correlation matrix
correlationMatrix <- cor(GermanCredit[,1:9])
# printing the correlation matrix
print(correlationMatrix)
# finding the attributes that are highly corrected
filterCorrelation <- findCorrelation(correlationMatrix, cutoff=0.5)
# print indexes of highly correlated fields
print(filterCorrelation)
#Loading the library
library(caret)
# load the German Credit Data
data(GermanCredit)
# calculating the correlation matrix
correlationMatrix <- cor(GermanCredit[,1:9])
# printing the correlation matrix
print(correlationMatrix)
# finding the attributes that are highly corrected
filterCorrelation <- findCorrelation(correlationMatrix, cutoff=0.5)
# print indexes of highly correlated fields
print(filterCorrelation)
print(correlationMatrix)
# finding the attributes that are highly corrected
# print indexes of highly correlated fields
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.5)
print(highlyCorrelated)
print(correlationMatrix)
# finding the attributes that are highly corrected
# print indexes of highly correlated fields
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff>=0.5)
install.packages("itunesr")
install.packages("itunesr")
install.packages("itunesr")
install.packages("textfeatures")
install.packages("tidyverse")
library(itunesr)
library(textfeatures)
library(tidyverse)
## the text is a review of a product
text_data <- c(
"This product was delivered very fast",
"TODAY WE MAKE AMERICA GREAT AGAIN!",
paste("The product works very efficiently"),
paste("The product saves us a lot of time"),
paste("The seller arranged a timely delivery")
)
## get the text features of a sample character vector
textfeatures(text_data)
## data frame with a character vector named "text"
df <- data.frame(
id = c(1, 2, 3),
text = c("this is A!\t sEntence https://github.com about #rstats @github",
"and another sentence here",
"The following list:\n- one\n- two\n- three\nOkay!?!"),
stringsAsFactors = FALSE
)
## Generate the text features
features=textfeatures(df)
#print the text features
glimpse(features)
library(MASS)
#Train a LDA
model <- lda(GermanCredit[,10]~., data = GermanCredit[,1:9])
library(MASS)
data("GermanCredit")
#Train a LDA
model <- lda(GermanCredit[,10]~., data = GermanCredit[,1:9])
#Print the model summary
Model
library(MASS)
data("GermanCredit")
#Train a LDA
model <- lda(GermanCredit[,10]~., data = GermanCredit[,1:9])
#Print the model summary
model
library(mlbench)
data(PimaIndiansDiabetes)
plot(PimaIndiansDiabetes$glucose, PimaIndiansDiabetes$pressure, col="red", xlab = "Glucose", ylab = "Pressure", pch=16, main = "Pearson Correlation")
library(mlbench)
data(PimaIndiansDiabetes)
plot(PimaIndiansDiabetes$glucose, PimaIndiansDiabetes$pressure, col="red", xlab = "Glucose", ylab = "Pressure", pch=16, main = "Pearson Correlation")
data(Sonar)
plot(Sonar$V4, Sonar$V3, col="red", xlab = "V4",
ylab = "V3", pch=16, main = "Pearson Correlation")
library(mlbench)
data(PimaIndiansDiabetes)
plot(PimaIndiansDiabetes$glucose, PimaIndiansDiabetes$pressure, col="red", xlab = "Glucose", ylab = "Pressure", pch=16, main = "Pearson Correlation")
data(Sonar)
plot(Sonar$V4, Sonar$V3, col="red", xlab = "V4",
ylab = "V3", pch=16, main = "Pearson Correlation")
library(mlbench)
data(PimaIndiansDiabetes)
plot(PimaIndiansDiabetes$glucose, PimaIndiansDiabetes$pressure, col="red", xlab = "Glucose", ylab = "Pressure", pch=16, main = "Pearson Correlation")
data(Sonar)
plot(Sonar$V4, Sonar$V3, col="red", xlab = "V4",
ylab = "V3", pch=16, main = "Pearson Correlation")
library(mlbench)
data(PimaIndiansDiabetes)
plot(PimaIndiansDiabetes$glucose, PimaIndiansDiabetes$pressure, col="red", xlab = "Glucose", ylab = "Pressure", pch=16, main = "Pearson Correlation")
data(Sonar)
plot(Sonar$V4, Sonar$V3, col="red", xlab = "Pregnant",
ylab = "Age", pch=16, main = "Pearson Correlation")
library(mlbench)
data(PimaIndiansDiabetes)
plot(PimaIndiansDiabetes$glucose, PimaIndiansDiabetes$pressure, col="red", xlab = "Glucose", ylab = "Pressure", pch=16, main = "Pearson Correlation")
library(mlbench)
data(PimaIndiansDiabetes)
plot(PimaIndiansDiabetes$glucose, PimaIndiansDiabetes$pressure, col="red", xlab = "Glucose", ylab = "Pressure", pch=16, main = "Pearson Correlation")
plot(PimaIndiansDiabetes$pregnant, PimaIndiansDiabetes$age, col="red", xlab = "Pregnant", ylab = "Age", pch=16, main = "Pearson Correlation")
plot(PimaIndiansDiabetes$glucose, PimaIndiansDiabetes$pressure, col="red", xlab = "Glucose", ylab = "Pressure", pch=16, main = "Pearson Correlation")
data(Sonar)
plot(Sonar$V4, Sonar$V3, col="red", xlab = "v4",
ylab = "v3", pch=16, main = "Pearson Correlation")
library(caret)
#Calculating P Value
cor.test(Sonar$V4, Sonar$V3)
set.seed(7)
install.packages("e1071")
set.seed(7)
install.packages("e1071")
install.packages("randomForest")
library(e1071)
library(randomForest)
# load the library
library(mlbench)
library(caret)
data("GermanCredit")
# Use random forest as the method
method_fn <- rfeControl(functions=rfFuncs, method="cv", number=9)
# run the Recursive Feature Elimination algorithm
output <- rfe(GermanCredit[,1:9], GermanCredit[,10], sizes=c(1:9), rfeControl=method_fn)
# print the output
print(output)
